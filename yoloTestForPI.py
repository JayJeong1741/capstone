import cv2
from picamera2 import Picamera2
from ultralytics import YOLO
import socketio
import base64
import threading
import time
import json
import requests
from datetime import datetime, timedelta
import pygame

# Socket.IO í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
sio = socketio.Client()
id = "9"
cid = "26"
idCid = id + "&" + cid
sessionId = ""
room = ""

# Picamera2 ì´ˆê¸°í™”
picam2 = Picamera2()
picam2.preview_configuration.main.size = (640, 640)  # í•´ìƒë„ ê°ì†Œ
picam2.preview_configuration.main.format = "RGB888"
picam2.preview_configuration.align()
picam2.configure("preview")
picam2.start()

# ì „ì—­ ë³€ìˆ˜
running = True
object_states = {}
frame_lock = threading.Lock()
current_frame = None
room_states = {}
population = 0
last_sent_time = datetime.now()
detection_duration = 3
target_classes = ['guideDog', 'dog', 'fallen', 'whiteCane', 'carAccident', 'person', 'wheelChair', 'crutches', 'gudieWalker']
min_detections = 2
population_window = timedelta(seconds=120)
active_person_ids = {}

# ì˜¤ë””ì˜¤ ìºì‹±
pygame.mixer.init(frequency=44100, size=-16, channels=2, buffer=4096)
audio_cache = {
    'wait': pygame.mixer.Sound("wait.mp3"),
    'done': pygame.mixer.Sound("mp3/done.mp3"),
    'beep': pygame.mixer.Sound("mp3/beep.mp3"),
    'plz': pygame.mixer.Sound("mp3/plz.mp3")
}
print("ğŸµ pygame.mixer ë° ì˜¤ë””ì˜¤ íŒŒì¼ ìºì‹± ì™„ë£Œ")

def setTime(class_name):
    """ì˜¤ë””ì˜¤ ì¬ìƒ ì‹œí€€ìŠ¤ ì²˜ë¦¬"""
    try:
        if class_name in ['guideDog', 'whiteCane']:
            audio_cache['wait'].play()
            time.sleep(12)
            audio_cache['done'].play()
            time.sleep(3)
            start_time = time.time()
            while time.time() - start_time < 20:
                audio_cache['beep'].play()
                time.sleep(7)
        elif class_name in ['crutches', 'wheelChair']:
            audio_cache['wait'].play()
            time.sleep(12)
            audio_cache['plz'].play()
            start_time = time.time()
            while time.time() - start_time < 25:
                audio_cache['plz'].play()
                time.sleep(10)
    except Exception as e:
        print(f"âŒ ì˜¤ë””ì˜¤ ì¬ìƒ ì—ëŸ¬: {e}")

def cleanup_states():
    """ì˜¤ë˜ëœ ê°ì²´ ìƒíƒœ ì •ë¦¬"""
    current_time = time.time()
    for obj_key in list(object_states.keys()):
        state = object_states[obj_key]
        if current_time - state['start_time'] > 300:  # 5ë¶„ ì´ìƒëœ í•­ëª© ì œê±°
            del object_states[obj_key]
            print(f"ğŸ—‘ï¸ {obj_key} ìƒíƒœ ì •ë¦¬")

def object_detection():
    """ê°ì²´ íƒì§€ ë° ìƒíƒœ ê´€ë¦¬ í•¨ìˆ˜"""
    global running, object_states, current_frame, last_sent_time, population, active_person_ids
    try:
        model = YOLO("model/capstone2.2_ncnn_model")
        frame_count = 0
        print("ğŸ” ê°ì²´ íƒì§€ ì‹œì‘...")

        while running:
            frame = picam2.capture_array()
            if frame is None:
                print("âŒ í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨")
                break

            frame_count += 1
            if frame_count % 3 != 0:  # í”„ë ˆì„ ìŠ¤í‚µ
                continue

            results = model.track(source=frame, conf=0.7, iou=0.45, persist=True)
            annotated_frame = results[0].plot()

            with frame_lock:
                current_frame = annotated_frame  # ì–•ì€ ë³µì‚¬

            current_objects = set()
            current_time = time.time()
            current_datetime = datetime.now()

            for result in results:
                for box in result.boxes:
                    if box.id is None:
                        continue
                    class_id = int(box.cls[0])
                    class_name = result.names[class_id]
                    obj_id = int(box.id)
                    if class_name in target_classes:
                        current_objects.add((class_name, obj_id))

            cleanup_states()
            manage_population(current_objects, current_datetime)

            for class_name, obj_id in current_objects:
                obj_key = f"{class_name}_{obj_id}"
                if obj_key not in object_states:
                    object_states[obj_key] = {
                        'class': class_name,
                        'is_detected': False,
                        'start_time': 0,
                        'has_sent': False,
                        'count': 0
                    }

                state = object_states[obj_key]
                state['count'] += 1
                if state['count'] >= min_detections and not state['is_detected']:
                    state['start_time'] = current_time
                    state['is_detected'] = True
                    print(f"ğŸš€ {class_name} (ID: {obj_id}) íƒì§€ ì‹œì‘")

                if state['is_detected'] and not state['has_sent'] and state['class'] != 'person':
                    elapsed_time = current_time - state['start_time']
                    if elapsed_time >= detection_duration:
                        print(f"ğŸš¨ {class_name} (ID: {obj_id}) 3ì´ˆ ì´ìƒ íƒì§€ë¨")
                        data = {"id": int(id), "cid": int(cid), "cls": class_name}
                        json_str = json.dumps(data)
                        if class_name in ['fallen', 'carAccident']:
                            sio.emit("emergency_detected", json_str)
                            state['has_sent'] = True
                        else:
                            threading.Thread(target=setTime, args=(class_name,), daemon=True).start()
                            state['has_sent'] = True

            for obj_key in list(object_states.keys()):
                class_name, obj_id = obj_key.split('_')
                obj_id = int(obj_id)
                if (class_name, obj_id) not in current_objects:
                    state = object_states[obj_key]
                    if state['is_detected']:
                        print(f"â„¹ï¸ {class_name} (ID: {obj_id}) íƒì§€ ì¤‘ë‹¨")
                        del object_states[obj_key]

            inference_time = results[0].speed['inference']
            fps = 1000 / inference_time if inference_time > 0 else 0
            cv2.putText(annotated_frame, f'FPS: {fps:.1f}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)

            cv2.imwrite("debug_frame.jpg", annotated_frame)
            cv2.imshow("Camera", annotated_frame)
            if cv2.waitKey(1) & 0xFF == ord("q"):
                running = False
                break

            time.sleep(0.01)

    except Exception as e:
        print(f"âŒ ê°ì²´ íƒì§€ ì—ëŸ¬: {e}")
    finally:
        cleanup_camera()

def manage_population(current_objects, current_datetime):
    """ì¸êµ¬ ìˆ˜ ê´€ë¦¬ ë° ì „ì†¡ í•¨ìˆ˜"""
    global population, last_sent_time, active_person_ids
    for class_name, obj_id in current_objects:
        if class_name == 'person':
            if obj_id not in active_person_ids:
                active_person_ids[obj_id] = {'last_seen': current_datetime, 'count': 0}
            active_person_ids[obj_id]['last_seen'] = current_datetime
            active_person_ids[obj_id]['count'] += 1
            if active_person_ids[obj_id]['count'] == min_detections:
                population += 1
                print(f"ğŸ‘¤ ì‚¬ëŒ (ID: {obj_id}) ì•ˆì •ì  íƒì§€, population: {population}")

    expired_ids = [
        obj_id for obj_id, info in active_person_ids.items()
        if (current_datetime - info['last_seen']) > timedelta(seconds=10)
    ]
    for obj_id in expired_ids:
        del active_person_ids[obj_id]
        print(f"ğŸ—‘ï¸ ì‚¬ëŒ (ID: {obj_id}) íƒì§€ ë§Œë£Œ")

    if current_datetime - last_sent_time >= population_window:
        send_traffic(population, current_datetime)
        population = 0
        last_sent_time = current_datetime
        print("ğŸ“Š population ì „ì†¡ ì™„ë£Œ")

def send_traffic(population, timestamp):
    """ì¸êµ¬ ìˆ˜ ë°ì´í„°ë¥¼ ì„œë²„ë¡œ ì „ì†¡"""
    url = "http://localhost:8080/main/api/traffic"
    data = {
        "id": {"id": id, "cid": cid, "date": timestamp.isoformat()},
        "population": population
    }
    headers = {"Content-Type": "application/json"}
    try:
        response = requests.post(url, json=data, headers=headers)
        print(f"ğŸ“¤ ì¸êµ¬ ìˆ˜ ì „ì†¡: status={response.status_code}")
    except Exception as e:
        print(f"âŒ ì¸êµ¬ ìˆ˜ ì „ì†¡ ì—ëŸ¬: {e}")

def cleanup_camera():
    """ì¹´ë©”ë¼ ë¦¬ì†ŒìŠ¤ í•´ì œ"""
    global picam2
    if picam2 is not None:
        picam2.stop()
        picam2.close()
        print("ğŸ“· ì¹´ë©”ë¼ ë¦¬ì†ŒìŠ¤ í•´ì œ")
    cv2.destroyAllWindows()

@sio.event
def connect():
    print("âœ… ì„œë²„ ì—°ê²° ì„±ê³µ")

@sio.event
def connection(sessionInfo):
    global sessionId, room
    sessionId = sessionInfo
    room = sessionId + idCid
    print(f"sessionId: {sessionId}, room: {room}")
    sio.emit("connectionSuccess", room)

@sio.event
def connect_error(data):
    print(f"âŒ ì—°ê²° ì‹¤íŒ¨: {data}")

@sio.event
def disconnect():
    global running, room_states
    print("ğŸ”Œ ì„œë²„ ì—°ê²° ì¢…ë£Œ")
    running = False
    for room_id in list(room_states.keys()):
        room_states[room_id]["send_frames_enabled"] = False
    cleanup_camera()

@sio.on("connected")
def on_connected():
    print("ğŸ‰ ì„œë²„ë¡œë¶€í„° 'connected' ì´ë²¤íŠ¸ ìˆ˜ì‹ ")

@sio.on("videoCall")
def start_sending_frames(data):
    room_id = data
    if room_id not in room_states or not room_states[room_id]["send_frames_enabled"]:
        room_states[room_id] = {"send_frames_enabled": True, "thread": None}
        room_states[room_id]["thread"] = threading.Thread(
            target=send_frames, args=(room_id,), daemon=True
        )
        room_states[room_id]["thread"].start()
        print(f"ğŸ“± videoCall: {room_id}ì—ì„œ í”„ë ˆì„ ì „ì†¡ ì‹œì‘")

@sio.on("stopVideo")
def stop_sending_frames(data):
    if data in room_states:
        room_states[data]["send_frames_enabled"] = False
        print(f"ğŸ›‘ stopVideo: {data}ì—ì„œ í”„ë ˆì„ ì „ì†¡ ì¤‘ë‹¨")

def send_frames(room_id):
    """í”„ë ˆì„ ì „ì†¡ í•¨ìˆ˜"""
    global running, current_frame
    while room_states.get(room_id, {}).get("send_frames_enabled", False):
        with frame_lock:
            frame = current_frame if current_frame is not None else None
        if frame is None:
            time.sleep(0.1)
            continue
        _, buffer = cv2.imencode(".jpg", frame, [int(cv2.IMWRITE_JPEG_QUALITY), 70])
        frame_data = base64.b64encode(buffer).decode("utf-8")
        sio.emit("frame", {"room_id": room_id, "data": frame_data})
        time.sleep(0.1)  # 10FPSë¡œ ì „ì†¡

if __name__ == "__main__":
    try:
        threading.Thread(target=object_detection, daemon=True).start()
        print("ğŸ”„ ì„œë²„ ì—°ê²° ì‹œë„...")
        sio.connect("http://localhost:3000")
        sio.emit("connectionForAlarm", cid)
        sio.wait()
    except KeyboardInterrupt:
        print("âš ï¸ í‚¤ë³´ë“œ ì¸í„°ëŸ½íŠ¸ ì¢…ë£Œ")
    except Exception as e:
        print(f"âš ï¸ í”„ë¡œê·¸ë¨ ì˜¤ë¥˜: {e}")
    finally:
        running = False
        for room_id in list(room_states.keys()):
            room_states[room_id]["send_frames_enabled"] = False
        if sio.connected:
            sio.disconnect()
        cleanup_camera()
        pygame.mixer.quit()
        print("ğŸ‘‹ í”„ë¡œê·¸ë¨ ì¢…ë£Œ")