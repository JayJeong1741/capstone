import cv2
from picamera2 import Picamera2
from ultralytics import YOLO
import socketio
import base64
import threading
import platform
import time
import json
import requests
from datetime import datetime, timedelta

# Socket.IO í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
sio = socketio.Client()
id = "9"
cid = "26"
idCid = id + "&" + cid
sessionId = ""
room = ""

picam2 = Picamera2()
picam2.preview_configuration.main.size = (640, 360)
picam2.preview_configuration.main.format = "RGB888"
picam2.preview_configuration.align()
picam2.configure("preview")
picam2.start()

# ì „ì—­ ë³€ìˆ˜
running = True
cap = None
object_states = {}  # ê°ì²´ IDë³„ ìƒíƒœ: {obj_key: {'class': cls, 'is_detected': bool, 'start_time': float, 'has_sent': bool, 'count': int}}
frame_lock = threading.Lock()  # í”„ë ˆì„ ì ‘ê·¼ ë™ê¸°í™”
current_frame = None  # ìµœì‹  í”„ë ˆì„ ì €ì¥
room_states = {}  # {room_id: {"send_frames_enabled": bool, "thread": Thread}}

population = 0
last_sent_time = datetime.now()
detection_duration = 3  # 3ì´ˆ ì´ìƒ íƒì§€í•´ì•¼ ì „ì†¡
target_classes = ['guideDog', 'dog', 'fallen', 'whiteCane', 'carAccident', 'person']  # íƒì§€ ëŒ€ìƒ í´ë˜ìŠ¤
min_detections = 2  # ì•ˆì •ì„±: 2í”„ë ˆì„ ì´ìƒ íƒì§€
population_window = timedelta(seconds=120)  # ì¸êµ¬ ìˆ˜ ê³„ì‚° ì‹œê°„ ì°½
active_person_ids = {}  # {obj_id: {'last_seen': datetime, 'count': int}} for person tracking

def object_detection():
    """ê°ì²´ íƒì§€ ë° ìƒíƒœ ê´€ë¦¬ í•¨ìˆ˜"""
    global running, cap, object_states, current_frame, last_sent_time, population, active_person_ids

    try:
        # YOLO ëª¨ë¸ ë¡œë”©
        model = YOLO("capstone2.0_ncnn_model")
        frame_count = 0

        print("ğŸ” ê°ì²´ íƒì§€ ì‹œì‘...")

        while running:
            ret, frame = picam2.capture_array()
            if not ret:
                print("âŒ ì›¹ìº ì—ì„œ í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                break

            frame_count += 1
            if frame_count % 2 != 0:
                continue  # 2í”„ë ˆì„ë§ˆë‹¤ 1í”„ë ˆì„ ì²˜ë¦¬

            # YOLO ê°ì²´ ì¶”ì 
            results = model.track(source=frame, conf=0.7, iou=0.45, persist=True)
            annotated_frame = results[0].plot()

            # í˜„ì¬ í”„ë ˆì„ ì €ì¥
            with frame_lock:
                current_frame = annotated_frame.copy()

            # í˜„ì¬ í”„ë ˆì„ì—ì„œ íƒì§€ëœ ê°ì²´
            current_objects = set()  # (class_name, obj_id)
            current_time = time.time()
            current_datetime = datetime.now()

            print("======================")
            for result in results:
                for box in result.boxes:
                    if box.id is None:
                        continue
                    class_id = int(box.cls[0])
                    class_name = result.names[class_id]
                    obj_id = int(box.id)
                    print(f"{class_name} (ID: {obj_id}), {box.conf[0]:.2f}, {box.xyxy[0]}")
                    if class_name in target_classes:
                        current_objects.add((class_name, obj_id))
            print("======================")

            # ì¸êµ¬ ìˆ˜ ê´€ë¦¬
            manage_population(current_objects, current_datetime)

            # íƒì§€ ìƒíƒœ ì²˜ë¦¬ ë° ë©”ì‹œì§€ ì „ì†¡
            for class_name, obj_id in current_objects:
                obj_key = f"{class_name}_{obj_id}"
                if obj_key not in object_states:
                    object_states[obj_key] = {
                        'class': class_name,
                        'is_detected': False,
                        'start_time': 0,
                        'has_sent': False,
                        'count': 0
                    }

                state = object_states[obj_key]
                state['count'] += 1
                if state['count'] >= min_detections and not state['is_detected']:
                    state['start_time'] = current_time
                    state['is_detected'] = True
                    print(f"ğŸš€ {class_name} (ID: {obj_id}) íƒì§€ ì‹œì‘, ì‹œì‘ ì‹œê°„: {state['start_time']:.2f}")

                if state['is_detected'] and not state['has_sent'] and state['class'] != 'person':
                    elapsed_time = current_time - state['start_time']
                    print(f"â±ï¸ {class_name} (ID: {obj_id}) ê²½ê³¼ ì‹œê°„: {elapsed_time:.2f}ì´ˆ")
                    if elapsed_time >= detection_duration:
                        print(f"ğŸš¨ {class_name} (ID: {obj_id}) 3ì´ˆ ì´ìƒ íƒì§€ë¨! ë©”ì‹œì§€ ì „ì†¡...")
                        data = {
                            "id": int(id),
                            "cid": int(cid),
                            "cls": class_name,
                        }
                        json_str = json.dumps(data)
                        if class_name == 'fallen' or class_name == 'carAccident':
                            sio.emit("emergency_detected", json_str)
                            state['has_sent'] = True

            # ì‚¬ë¼ì§„ ê°ì²´ ì²˜ë¦¬
            for obj_key in list(object_states.keys()):
                class_name, obj_id = obj_key.split('_')
                obj_id = int(obj_id)
                if (class_name, obj_id) not in current_objects:
                    state = object_states[obj_key]
                    if state['is_detected']:
                        print(f"â„¹ï¸ {class_name} (ID: {obj_id}) íƒì§€ ì¤‘ë‹¨, ìƒíƒœ ë¦¬ì…‹")
                        del object_states[obj_key]

            # FPS í‘œì‹œ
            inference_time = results[0].speed['inference']
            fps = 1000 / inference_time if inference_time > 0 else 0
            text = f'FPS: {fps:.1f}'
            font = cv2.FONT_HERSHEY_SIMPLEX
            text_size = cv2.getTextSize(text, font, 1, 2)[0]
            text_x = annotated_frame.shape[1] - text_size[0] - 10
            text_y = text_size[1] + 10
            cv2.putText(annotated_frame, text, (text_x, text_y), font, 1, (255, 255, 255), 2, cv2.LINE_AA)

            # ë””ë²„ê¹…ìš© ì €ì¥
            cv2.imwrite("debug_frame.jpg", annotated_frame)

            # í™”ë©´ í‘œì‹œ (macOS ì œì™¸)
            if platform.system() != "Darwin":
                cv2.imshow("Camera", annotated_frame)
                if cv2.waitKey(1) & 0xFF == ord("q"):
                    running = False
                    break

            time.sleep(0.01)

    except Exception as e:
        print(f"âŒ ê°ì²´ íƒì§€ ì—ëŸ¬: {e}")
    finally:
        cleanup_camera()
        print("ğŸ” ê°ì²´ íƒì§€ ì¢…ë£Œ")

def manage_population(current_objects, current_datetime):
    """ì¸êµ¬ ìˆ˜ ê´€ë¦¬ ë° ì „ì†¡ í•¨ìˆ˜"""
    global population, last_sent_time, active_person_ids

    # í˜„ì¬ í”„ë ˆì„ì—ì„œ íƒì§€ëœ ì‚¬ëŒ ì²˜ë¦¬
    for class_name, obj_id in current_objects:
        if class_name == 'person':
            if obj_id not in active_person_ids:
                active_person_ids[obj_id] = {'last_seen': current_datetime, 'count': 0}
            active_person_ids[obj_id]['last_seen'] = current_datetime
            active_person_ids[obj_id]['count'] += 1
            if active_person_ids[obj_id]['count'] == min_detections:
                population += 1
                print(f"ğŸ‘¤ ì‚¬ëŒ (ID: {obj_id}) ì•ˆì •ì ìœ¼ë¡œ íƒì§€ë¨, population: {population}")

    # ë§Œë£Œëœ ì‚¬ëŒ ID ì œê±°
    expired_ids = [
        obj_id for obj_id, info in active_person_ids.items()
        if (current_datetime - info['last_seen']) > timedelta(seconds=10)
    ]
    for obj_id in expired_ids:
        del active_person_ids[obj_id]
        print(f"ğŸ—‘ï¸ ì‚¬ëŒ (ID: {obj_id}) íƒì§€ ë§Œë£Œ, ì œê±°ë¨")

    # 1ë¶„ë§ˆë‹¤ ì¸êµ¬ ìˆ˜ ì „ì†¡
    if current_datetime - last_sent_time >= population_window:
        send_traffic(population, current_datetime)
        population = 0
        last_sent_time = current_datetime
        print("ğŸ“Š population ì´ˆê¸°í™” ë° ì „ì†¡ ì™„ë£Œ")

def send_traffic(population, timestamp):
    """ì¸êµ¬ ìˆ˜ ë°ì´í„°ë¥¼ ì„œë²„ë¡œ ì „ì†¡"""
    url = "http://localhost:8080/main/api/traffic"
    data = {
        "id": {
            "id": id,
            "cid": cid,
            "date": timestamp.isoformat()
        },
        "population": population
    }
    headers = {"Content-Type": "application/json"}
    try:
        response = requests.post(url, json=data, headers=headers)
        print(f"ğŸ“¤ ì¸êµ¬ ìˆ˜ ì „ì†¡: status={response.status_code}, response={response.text}")
    except Exception as e:
        print(f"âŒ ì¸êµ¬ ìˆ˜ ì „ì†¡ ì—ëŸ¬: {e}")

def cleanup_camera():
    """ì¹´ë©”ë¼ ë¦¬ì†ŒìŠ¤ í•´ì œ"""
    global cap
    if cap is not None and cap.isOpened():
        cap.release()
        print("ğŸ“· ì¹´ë©”ë¼ ë¦¬ì†ŒìŠ¤ í•´ì œ ì™„ë£Œ")
    cv2.destroyAllWindows()

# Socket.IO ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
@sio.event
def connect():
    print("âœ… ì„œë²„ì— ì—°ê²°ë¨")

@sio.event
def connection(sessionInfo):
    global sessionId, room
    sessionId = sessionInfo
    room = sessionId + idCid
    print(f"sessionId: {sessionId}, room: {room}")
    sio.emit("connectionSuccess", room)

@sio.event
def connect_error(data):
    print("âŒ ì—°ê²° ì‹¤íŒ¨:", data)

@sio.event
def disconnect():
    global running, room_states
    print("ğŸ”Œ ì„œë²„ ì—°ê²° ì¢…ë£Œë¨")
    running = False
    for room_id in list(room_states.keys()):
        room_states[room_id]["send_frames_enabled"] = False
    cleanup_camera()

@sio.on("connected")
def on_connected():
    print("ğŸ‰ ì„œë²„ë¡œë¶€í„° 'connected' ì´ë²¤íŠ¸ ìˆ˜ì‹ !")

@sio.on("videoCall")
def start_sending_frames(data):
    room_id = data
    print(f"room info: {room_id}")
    if room_id not in room_states or not room_states[room_id]["send_frames_enabled"]:
        room_states[room_id] = {"send_frames_enabled": True, "thread": None}
        room_states[room_id]["thread"] = threading.Thread(
            target=send_frames, args=(room_id,), daemon=True
        )
        room_states[room_id]["thread"].start()
        print(f"ğŸ“± videoCall ì´ë²¤íŠ¸ ìˆ˜ì‹ : {room_id}ì—ì„œ í”„ë ˆì„ ì „ì†¡ ì‹œì‘")

@sio.on("stopVideo")
def stop_sending_frames(data):
    print(f"stopVideo: {data}")
    if data in room_states:
        room_states[data]["send_frames_enabled"] = False
        print(f"ğŸ›‘ stopVideo ì´ë²¤íŠ¸ ìˆ˜ì‹ : {data}ì—ì„œ í”„ë ˆì„ ì „ì†¡ ì¤‘ë‹¨")

def send_frames(room_id):
    """í”„ë ˆì„ ì „ì†¡ í•¨ìˆ˜"""
    global running, current_frame
    while room_states.get(room_id, {}).get("send_frames_enabled", False):
        with frame_lock:
            frame = current_frame.copy() if current_frame is not None else None
        if frame is None:
            print(f"{room_id} ë°©ì—ì„œ í”„ë ˆì„ ì—†ìŒ, ëŒ€ê¸° ì¤‘...")
            time.sleep(0.1)
            continue
        _, buffer = cv2.imencode(".jpg", frame)
        frame_data = base64.b64encode(buffer).decode("utf-8")
        print(f"í”„ë ˆì„ ì „ì†¡ ì‹œë„: room_id={room_id}, ë°ì´í„° í¬ê¸°={len(frame_data)}")
        sio.emit("frame", {"room_id": room_id, "data": frame_data})
        time.sleep(0.03)

if __name__ == "__main__":
    try:
        threading.Thread(target=object_detection, daemon=True).start()
        print("ğŸ”„ ì„œë²„ì— ì—°ê²° ì¤‘...")
        sio.connect("http://localhost:3000")
        sio.emit("connectionForAlarm", cid)
        sio.wait()
    except KeyboardInterrupt:
        print("âš ï¸ í‚¤ë³´ë“œ ì¸í„°ëŸ½íŠ¸ì— ì˜í•œ ì¢…ë£Œ")
    except Exception as e:
        print(f"âš ï¸ í”„ë¡œê·¸ë¨ ì˜¤ë¥˜: {e}")
    finally:
        running = False
        for room_id in list(room_states.keys()):
            room_states[room_id]["send_frames_enabled"] = False
        if sio.connected:
            sio.disconnect()
        cleanup_camera()
        print("ğŸ‘‹ í”„ë¡œê·¸ë¨ ì¢…ë£Œ")